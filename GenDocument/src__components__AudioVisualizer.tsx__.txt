# AudioVisualizer.tsx
'use client'

import { useEffect, useRef } from 'react'

interface AudioVisualizerProps {
  audioRef: React.RefObject<HTMLAudioElement>
  canvasRef: React.RefObject<HTMLCanvasElement>
  isPlaying: boolean
}

export default function AudioVisualizer({
  audioRef,
  canvasRef,
  isPlaying
}: AudioVisualizerProps) {
  const animationRef = useRef<number | null>(null)
  const analyserRef = useRef<AnalyserNode | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)

  useEffect(() => {
    const audioEl = audioRef.current
    const canvasEl = canvasRef.current

    if (!audioEl || !canvasEl) return

    const ensureAudioContext = async () => {
      // Crear contexto + analyser solo una vez
      if (!audioContextRef.current) {
        const Ctx =
          (window as any).AudioContext || (window as any).webkitAudioContext
        const ctx = new Ctx() as AudioContext
        const analyser = ctx.createAnalyser()

        analyser.fftSize = 256

        const source = ctx.createMediaElementSource(audioEl)
        source.connect(analyser)
        analyser.connect(ctx.destination)

        audioContextRef.current = ctx
        analyserRef.current = analyser
      }

      // MUY IMPORTANTE: asegurar que el contexto NO estÃ© suspendido
      if (audioContextRef.current?.state === 'suspended') {
        try {
          await audioContextRef.current.resume()
        } catch (e) {
          console.warn('No se pudo reanudar el AudioContext:', e)
        }
      }
    }

    const draw = () => {
      const analyser = analyserRef.current
      const canvas = canvasRef.current

      if (!analyser || !canvas) return

      const ctx = canvas.getContext('2d')
      if (!ctx) return

      // Ajustar tamaÃ±o del canvas al tamaÃ±o visible
      const { width, height } = canvas.getBoundingClientRect()
      if (canvas.width !== width || canvas.height !== height) {
        canvas.width = width
        canvas.height = height
      }

      const bufferLength = analyser.frequencyBinCount
      const dataArray = new Uint8Array(bufferLength)

      analyser.getByteFrequencyData(dataArray)

      ctx.fillStyle = 'rgba(0, 0, 0, 0.2)'
      ctx.fillRect(0, 0, canvas.width, canvas.height)

      const barWidth = (canvas.width / bufferLength) * 2.5
      let x = 0

      for (let i = 0; i < bufferLength; i++) {
        const value = dataArray[i]
        const barHeight = (value / 255) * canvas.height * 0.7

        const hue = (i / bufferLength) * 360
        ctx.fillStyle = `hsl(${hue}, 100%, 50%)`
        ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight)

        x += barWidth + 1
      }

      if (isPlaying) {
        animationRef.current = requestAnimationFrame(draw)
      }
    }

    let cancelled = false

    const start = async () => {
      if (!isPlaying) return
      await ensureAudioContext()
      if (!cancelled) {
        draw()
      }
    }

    if (isPlaying) {
      start()
    } else {
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current)
      }
    }

    return () => {
      cancelled = true
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current)
      }
    }
  }, [isPlaying, audioRef, canvasRef])

  return null
}

